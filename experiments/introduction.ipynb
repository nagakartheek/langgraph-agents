{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3eb8cd5-d804-4417-b9d6-9f40ab4266af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"AZURE_OPENAI_API_KEY\")\n",
    "_set_env(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b16e0-d5cb-4a1e-87e4-697e2634454a",
   "metadata": {},
   "source": [
    "Let's instantiate the LLM and generate outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de02831-dd58-433c-a20b-d445fb1531f1",
   "metadata": {},
   "source": [
    "There are many ways we can provide the input to these chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ef8b98-9a59-4e52-a0f2-c0d094372455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! ðŸ˜Š How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 9, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BKTmiGIOVSkzEyKBzeIat2DLupxxC', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-d47abac5-260f-4011-b5b9-381af1d5375e-0', usage_metadata={'input_tokens': 9, 'output_tokens': 11, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\", # replace with your model name from Azure Openai deployments\n",
    "    api_version=\"2024-10-21\",\n",
    "    temperature=0\n",
    ")\n",
    "# provide a string as input\n",
    "llm.invoke(\"Hi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad4c53-5ad6-46fe-8b0b-4b9e25f20bdb",
   "metadata": {},
   "source": [
    "There is another way to invoke LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355bd1ab-ef60-4801-bdc6-829ccec68923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! ðŸ˜Š How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 12, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BKTmi1Ty5XdhnUKbdBy80IVbV0e5H', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-d538d874-7b84-40a8-8c52-73e7949ab4bc-0', usage_metadata={'input_tokens': 12, 'output_tokens': 11, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# list of messages (Langchain way)\n",
    "## let's create the messages with `name`s (labels) inside a list\n",
    "msg = HumanMessage(content=\"Hello GPT!\", name=\"MS\")\n",
    "messages = [msg]\n",
    "\n",
    "# invoke with a list of messages \n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9119aad-f179-46a5-8a55-50719b4d1c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||Hello|!| ðŸ˜Š| How| can| I| assist| you| today|?||"
     ]
    }
   ],
   "source": [
    "# we can also stream the output the chatgpt way\n",
    "for chunk in llm.stream(messages):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a55ce-b624-4ac0-bba3-48f9523e457e",
   "metadata": {},
   "source": [
    "### Create the graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a006963-785f-4c91-8b2a-0c795b546f69",
   "metadata": {},
   "source": [
    "First of all, let's write an utility to draw the graphs built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f42d54e-ecc6-4578-bc85-062d97b91f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, Markdown\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "def draw_graph(compiled_graph):\n",
    "    try:\n",
    "        return Image(compiled_graph.get_graph(xray=1).draw_mermaid_png())\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d954217d-2393-4408-a7c0-55b0727abb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "def my_node(state, config):\n",
    "    # this node increments \"x\" by 1\n",
    "   return {\"x\": state[\"x\"] + 1}\n",
    "\n",
    "# we can build state graph of type dict/typed dict/pydantic model/dataclass\n",
    "# let's start with dict and build a simple graph of 1 node\n",
    "builder = StateGraph(dict)\n",
    "builder.add_node(my_node)  # node name will be 'my_node'\n",
    "builder.add_edge(START, \"my_node\")\n",
    "graph = builder.compile()\n",
    "\n",
    "# draw the graph\n",
    "# display(draw_graph(graph))\n",
    "\n",
    "# pass the input to the graph\n",
    "graph.invoke({\"x\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e2d964-89cd-41ad-bc96-72274d512b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ConfigurableFieldSpec(id='r', annotation=<class 'float'>, name=None, description=None, default=None, is_shared=False, dependencies=None)]\n",
      "{'x': [0.5, 0.75]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "def reducer(a: list, b: int | None) -> list:\n",
    "    if b is not None:\n",
    "        return a + [b]\n",
    "    return a\n",
    "\n",
    "class State(TypedDict):\n",
    "    x: Annotated[list, reducer]\n",
    "\n",
    "class ConfigSchema(TypedDict):\n",
    "    r: float\n",
    "\n",
    "graph = StateGraph(State, config_schema=ConfigSchema)\n",
    "\n",
    "def node(state: State, config: RunnableConfig) -> dict:\n",
    "    r = config[\"configurable\"].get(\"r\", 1.0)\n",
    "    x = state[\"x\"][-1]\n",
    "    next_value = x * r * (1 - x)\n",
    "    return {\"x\": next_value}\n",
    "    \n",
    "graph.add_node(\"A\", node)\n",
    "\n",
    "# Equivalent to calling add_edge(START, \"A\")\n",
    "graph.set_entry_point(\"A\")\n",
    "\n",
    "# Equivalent to calling add_edge(\"A\", END)\n",
    "graph.set_finish_point(\"A\")\n",
    "compiled = graph.compile()\n",
    "\n",
    "# display(Image(compiled.get_graph(xray=1).draw_png()))\n",
    "print(compiled.config_specs)\n",
    "\n",
    "step1 = compiled.invoke({\"x\": 0.5}, {\"configurable\": {\"r\": 3.0}})\n",
    "print(step1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701a42d-316f-419b-b133-e464b0beaf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1285f01-52b7-490f-b279-18e2c59047f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# State in LangGraph can be a TypedDict, Pydantic model, or dataclass. \n",
    "class State(TypedDict):\n",
    "    messages: list[AnyMessage] # define the type of the keys\n",
    "    extra_field: int\n",
    "\n",
    "def node(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    new_message = AIMessage(\"Hello!\")\n",
    "    # appends the new AI message to the existing messages\n",
    "    return {\"messages\": messages + [new_message], \"extra_field\": 10}\n",
    "\n",
    "# build and compile the graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(node)\n",
    "graph_builder.set_entry_point(\"node\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a2fbde1-0e01-43c7-a1c8-4cab47dcf9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello!', additional_kwargs={}, response_metadata={})],\n",
       " 'extra_field': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# send the input human message\n",
    "result = graph.invoke({\"messages\": [HumanMessage(\"Hi\")]})\n",
    "# the result should append the AImessage(\"Hello!\") along with the extra field\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8aab2-1147-4436-b9e9-8d6bbf307019",
   "metadata": {},
   "source": [
    "### Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250ceb81-0af0-4c27-88f0-50fb72204493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated\n",
    "from langgraph.graph import START\n",
    "\n",
    "\n",
    "def add(left, right):\n",
    "    \"\"\"Can also import `add` from the `operator` built-in.\"\"\"\n",
    "    return left + right\n",
    "\n",
    "# For TypedDict state schemas, we can define reducers by annotating the corresponding field of the state with a reducer function.\n",
    "class State(TypedDict):\n",
    "    # Each key in the state can have its own independent reducer function, \n",
    "    # which controls how updates from nodes are applied. \n",
    "    # If no reducer function is explicitly specified \n",
    "    # then it is assumed that all updates to the key should override it.\n",
    "    messages: Annotated[list[AnyMessage], add]\n",
    "    extra_field: int\n",
    "\n",
    "def node(state: State):\n",
    "    new_message = AIMessage(\"Hello!\")\n",
    "    return {\"messages\": [new_message], \"extra_field\": 10}\n",
    "\n",
    "# build and compile the graph with this single node\n",
    "graph = StateGraph(State).add_node(node).add_edge(START, \"node\").compile()\n",
    "\n",
    "# input HumanMessage\n",
    "result = graph.invoke({\"messages\": [HumanMessage(\"Hi\")]})\n",
    "\n",
    "# print each of the messages\n",
    "# we expect the input HumanMessage new AImessage\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ce7df-c360-4b43-9a41-32cdf225b99d",
   "metadata": {},
   "source": [
    "Can also use OpenAI style messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9f20f27-fcfd-43c4-8b4a-e1e218d5b56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    extra_field: int\n",
    "\n",
    "# the same can be represented by MessagesState\n",
    "class State(MessagesState):\n",
    "    extra_field: int\n",
    "\n",
    "\n",
    "def node(state: State):\n",
    "    new_message = AIMessage(\"Hello!\")\n",
    "    return {\"messages\": [new_message], \"extra_field\": 10}\n",
    "\n",
    "\n",
    "graph = StateGraph(State).add_node(node).set_entry_point(\"node\").compile()\n",
    "# can also invoke using openai style messages\n",
    "input_message = {\"role\": \"user\", \"content\": \"Hi\"}\n",
    "\n",
    "result = graph.invoke({\"messages\": [input_message]})\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc60bb-1d5b-425c-948c-dfc0e0911c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d235f40-2128-4e81-8d30-5eb84b641cb4",
   "metadata": {},
   "source": [
    "Add multiple nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f19e4-a459-4a47-b7aa-7a8f47753158",
   "metadata": {},
   "source": [
    "Build graph using `.add_sequence`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bc44d-4903-48a4-9bd2-960e80a9b68d",
   "metadata": {},
   "source": [
    "The following cells are equivalent\n",
    "```\n",
    "graph_builder = StateGraph(State).add_sequence([step_1, step_2, step_3])\n",
    "graph_builder.add_edge(START, \"step_1\")\n",
    "```\n",
    "and \n",
    "```\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(step_1)\n",
    "graph_builder.add_node(step_2)\n",
    "graph_builder.add_node(step_3)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"step_1\")\n",
    "graph_builder.add_edge(\"step_1\", \"step_2\")\n",
    "graph_builder.add_edge(\"step_2\", \"step_3\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e86b1e-d488-4503-b74e-cb8ee429ea16",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f15b6231-42c2-4027-a514-b627bf6f4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "from IPython.display import Image, display\n",
    "\n",
    "class State(TypedDict):\n",
    "    alist: Annotated[list, operator.add]\n",
    "    another_list: Annotated[list, operator.add]\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"a\", lambda _state: {\"another_list\": [\"hi\"]})\n",
    "builder.add_node(\"b\", lambda _state: {\"alist\": [\"there\"]})\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(START, \"a\")\n",
    "graph = builder.compile()\n",
    "\n",
    "# display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5ed836c-4a8d-4746-b500-ea3d762ed543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alist': ['Ex for stream_mode=\"values\"'], 'another_list': []}\n",
      "{'alist': ['Ex for stream_mode=\"values\"'], 'another_list': ['hi']}\n",
      "{'alist': ['Ex for stream_mode=\"values\"', 'there'], 'another_list': ['hi']}\n"
     ]
    }
   ],
   "source": [
    "# with stream mode values, prints all the values\n",
    "for event in graph.stream({\"alist\": ['Ex for stream_mode=\"values\"']}, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad690445-817a-481e-9d0e-7a8924c885a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'another_list': ['hi']}}\n",
      "{'b': {'alist': ['there']}}\n"
     ]
    }
   ],
   "source": [
    "# with stream mode updates, only the updates to the keys are printed\n",
    "for event in graph.stream({\"alist\": ['Ex for stream_mode=\"updates\"']}, stream_mode=\"updates\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9a8168b-23bb-4420-81a7-5e96bb31e7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'task', 'timestamp': '2025-04-09T18:14:05.214900+00:00', 'step': 1, 'payload': {'id': '0d910bb5-3ac7-cedf-941e-b32d858eb542', 'name': 'a', 'input': {'alist': ['Ex for stream_mode=\"debug\"'], 'another_list': []}, 'triggers': ('branch:to:a',)}}\n",
      "{'type': 'task_result', 'timestamp': '2025-04-09T18:14:05.222263+00:00', 'step': 1, 'payload': {'id': '0d910bb5-3ac7-cedf-941e-b32d858eb542', 'name': 'a', 'error': None, 'result': [('another_list', ['hi'])], 'interrupts': []}}\n",
      "{'type': 'task', 'timestamp': '2025-04-09T18:14:05.222263+00:00', 'step': 2, 'payload': {'id': 'ffea2e27-948f-a7fb-bdd5-a75eba0945f1', 'name': 'b', 'input': {'alist': ['Ex for stream_mode=\"debug\"'], 'another_list': ['hi']}, 'triggers': ('branch:to:b',)}}\n",
      "{'type': 'task_result', 'timestamp': '2025-04-09T18:14:05.224978+00:00', 'step': 2, 'payload': {'id': 'ffea2e27-948f-a7fb-bdd5-a75eba0945f1', 'name': 'b', 'error': None, 'result': [('alist', ['there'])], 'interrupts': []}}\n"
     ]
    }
   ],
   "source": [
    "# debug -> task (state input) and task_result (output) and triggers\n",
    "for event in graph.stream({\"alist\": ['Ex for stream_mode=\"debug\"']}, stream_mode=\"debug\"):\n",
    "    print(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab922a8f-d3a8-4418-8177-325ccb6df2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_data': 'foo'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import StreamWriter\n",
    "\n",
    "def node_a(state: State, writer: StreamWriter):\n",
    "    # can also add custom writers\n",
    "    writer({\"custom_data\": \"foo\"})\n",
    "    return {\"alist\": [\"hi\"]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"a\", node_a)\n",
    "builder.add_edge(START, \"a\")\n",
    "graph = builder.compile()\n",
    "\n",
    "for event in graph.stream({\"alist\": ['Ex for stream_mode=\"custom\"']}, stream_mode=\"custom\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fb59c21-e956-46ac-9354-45c4b2b63a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' capital', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' France', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='Paris', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0'}, id='run-8611d7bf-897b-4919-83eb-80b450585765'), {'langgraph_step': 1, 'langgraph_node': 'a', 'langgraph_triggers': ('branch:to:a',), 'langgraph_path': ('__pregel_pull', 'a'), 'langgraph_checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'checkpoint_ns': 'a:2b0b4712-24d0-5341-8367-4f04c67db280', 'ls_provider': 'azure', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "def node_a(state: State):\n",
    "    response = llm.invoke(state[\"question\"])\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"a\", node_a)\n",
    "builder.add_edge(START, \"a\")\n",
    "graph = builder.compile()\n",
    "\n",
    "# messages -> LLM streaming mode\n",
    "for event in graph.stream({\"question\": \"What is the capital of France?\"}, stream_mode=\"messages\"):\n",
    "    print(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a243ef-f935-4623-98c5-042e7200983a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b63aa1bc-8c68-4ee5-819d-32e12c5b8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "class State(TypedDict):\n",
    "    alist: Annotated[list, operator.add]\n",
    "    another_list: Annotated[list, operator.add]\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"a\", lambda _state: {\"another_list\": [\"hi\"]})\n",
    "builder.add_node(\"b\", lambda _state: {\"alist\": [\"there\"]})\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(START, \"a\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01a62a72-e71a-4739-8f59-9fcf28ffca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alist': ['Ex for stream_mode=\"values\"'], 'another_list': []}\n",
      "{'alist': ['Ex for stream_mode=\"values\"'], 'another_list': ['hi']}\n",
      "{'alist': ['Ex for stream_mode=\"values\"', 'there'], 'another_list': ['hi']}\n"
     ]
    }
   ],
   "source": [
    "async for event in graph.astream({\"alist\": ['Ex for stream_mode=\"values\"']}, stream_mode=\"values\"):\n",
    "    print(event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a63ef-77ef-4092-a201-8be10f36902c",
   "metadata": {},
   "source": [
    "`invoke` to just fetch the output directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c14795fb-bc62-4b03-8fbb-9896cd98da4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alist': ['Ex for stream_mode=\"values\"', 'there'], 'another_list': ['hi']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly print the result with invoke\n",
    "graph.invoke({\"alist\": ['Ex for stream_mode=\"values\"']}, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43a76f12-d870-48e2-b36f-16da060866cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': {'another_list': ['hi']}}, {'b': {'alist': ['there']}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only fetch the updates\n",
    "graph.invoke({\"alist\": ['Ex for stream_mode=\"values\"']}, stream_mode=\"updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6e626-591c-444d-be42-c23fa18749cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd6df855-3cc6-4e21-bb72-b65dd9db989f",
   "metadata": {},
   "source": [
    "Define different schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac43ccd4-a694-439a-b866-d2f77272dcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'bye'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# Define the schema for the input\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "# Define the schema for the output\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define the overall schema, combining both input and output\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Define the node that processes the input and generates an answer\n",
    "def answer_node(state: InputState):\n",
    "    # Example answer and an extra key\n",
    "    return {\"answer\": \"bye\", \"question\": state[\"question\"]}\n",
    "\n",
    "\n",
    "# Build the graph with input and output schemas specified\n",
    "builder = StateGraph(OverallState, input=InputState, output=OutputState)\n",
    "builder.add_node(answer_node)  # Add the answer node\n",
    "builder.add_edge(START, \"answer_node\")  # Define the starting edge\n",
    "builder.add_edge(\"answer_node\", END)  # Define the ending edge\n",
    "graph = builder.compile()  # Compile the graph\n",
    "\n",
    "# Invoke the graph with an input and print the result\n",
    "print(graph.invoke({\"question\": \"hi\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e466efd-ec7d-4704-aaad-353e845a1bee",
   "metadata": {},
   "source": [
    "### Conditional Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47ebe2fe-7fd7-41ba-b921-0fd4db3bc267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node A sees []\n",
      "Node B sees ['A']\n",
      "Node A sees ['A', 'B']\n",
      "Node B sees ['A', 'B', 'A']\n",
      "Node A sees ['A', 'B', 'A', 'B']\n",
      "Node B sees ['A', 'B', 'A', 'B', 'A']\n",
      "Node A sees ['A', 'B', 'A', 'B', 'A', 'B']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aggregate': ['A', 'B', 'A', 'B', 'A', 'B', 'A']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # The operator.add reducer fn makes this append-only\n",
    "    aggregate: Annotated[list, operator.add]\n",
    "\n",
    "\n",
    "def a(state: State):\n",
    "    print(f'Node A sees {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"A\"]}\n",
    "\n",
    "\n",
    "def b(state: State):\n",
    "    print(f'Node B sees {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"B\"]}\n",
    "\n",
    "\n",
    "# Define nodes\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(a)\n",
    "builder.add_node(b)\n",
    "\n",
    "\n",
    "# Define edges\n",
    "def route(state: State) -> Literal[\"b\", END]:\n",
    "    if len(state[\"aggregate\"]) < 7:\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_conditional_edges(\"a\", route)\n",
    "builder.add_edge(\"b\", \"a\")\n",
    "graph = builder.compile()\n",
    "\n",
    "graph.invoke({\"aggregate\": []})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7d8bc-6533-46b0-be01-3e1c573c9dc4",
   "metadata": {},
   "source": [
    "Impose Recursion limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1941e78e-9c9e-4565-bafa-8fe155d9c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node A sees []\n",
      "Node B sees ['A']\n",
      "Node A sees ['A', 'B']\n",
      "Node B sees ['A', 'B', 'A']\n",
      "Recursion Error\n"
     ]
    }
   ],
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "try:\n",
    "    graph.invoke({\"aggregate\": []}, {\"recursion_limit\": 4})\n",
    "except GraphRecursionError:\n",
    "    print(\"Recursion Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36deff2d-d4e1-4432-a7a8-a5eecf5a2dd3",
   "metadata": {},
   "source": [
    "### Run Nodes in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b680096-7882-4665-ad40-2ca692858527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding \"A\" to []\n",
      "Adding \"B\" to ['A']\n",
      "Adding \"C\" to ['A']\n",
      "Adding \"D\" to ['A', 'B', 'C']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aggregate': ['A', 'B', 'C', 'D']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangGraph offers native support for parallel execution of nodes, \n",
    "# which can significantly enhance the performance of graph-based workflows. \n",
    "# This parallelization is achieved through fan-out and fan-in mechanisms, \n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Any\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # The operator.add reducer fn makes this append-only\n",
    "    aggregate: Annotated[list, operator.add]\n",
    "\n",
    "\n",
    "def a(state: State):\n",
    "    print(f'Adding \"A\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"A\"]}\n",
    "\n",
    "\n",
    "def b(state: State):\n",
    "    print(f'Adding \"B\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"B\"]}\n",
    "\n",
    "\n",
    "def c(state: State):\n",
    "    print(f'Adding \"C\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"C\"]}\n",
    "\n",
    "\n",
    "def d(state: State):\n",
    "    print(f'Adding \"D\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"D\"]}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(a)\n",
    "builder.add_node(b)\n",
    "builder.add_node(c)\n",
    "builder.add_node(d)\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"d\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# Nodes \"b\" and \"c\" are executed concurrently in the same superstep. \n",
    "# Because they are in the same step, node \"d\" executes after both \"b\" and \"c\" are finished\n",
    "graph.invoke({\"aggregate\": []}, {\"configurable\": {\"thread_id\": \"foo\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3e6efe4-864c-483c-8d2a-ce347094a352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding \"A\" to []\n",
      "Adding \"B\" to ['A']\n",
      "Adding \"C\" to ['A']\n",
      "Adding \"B_2\" to ['A', 'B', 'C']\n",
      "Adding \"D\" to ['A', 'B', 'C', 'B_2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aggregate': ['A', 'B', 'C', 'B_2', 'D']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's add one more node to one of the parallel paths\n",
    "def b_2(state: State):\n",
    "    print(f'Adding \"B_2\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"B_2\"]}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(a)\n",
    "builder.add_node(b)\n",
    "builder.add_node(b_2)\n",
    "builder.add_node(c)\n",
    "builder.add_node(d)\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"b_2\")\n",
    "builder.add_edge([\"b_2\", \"c\"], \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# still b and c will remain in the same super-step\n",
    "graph.invoke({\"aggregate\": []})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18894e91-9082-461f-9d31-c7391a2587f2",
   "metadata": {},
   "source": [
    "### Conditional Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "002cdbd4-2605-49e1-b8ff-062dff9edf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding \"A\" to []\n",
      "Adding \"C\" to ['A']\n",
      "Adding \"D\" to ['A']\n",
      "Adding \"E\" to ['A', 'C', 'D']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aggregate': ['A', 'C', 'D', 'E'], 'which': 'cd'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    aggregate: Annotated[list, operator.add]\n",
    "    # Add a key to the state. We will set this key to determine\n",
    "    # how we branch.\n",
    "    which: str\n",
    "\n",
    "\n",
    "def a(state: State):\n",
    "    print(f'Adding \"A\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"A\"]}\n",
    "\n",
    "\n",
    "def b(state: State):\n",
    "    print(f'Adding \"B\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"B\"]}\n",
    "\n",
    "\n",
    "def c(state: State):\n",
    "    print(f'Adding \"C\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"C\"]}\n",
    "\n",
    "\n",
    "def d(state: State):\n",
    "    print(f'Adding \"D\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"D\"]}\n",
    "\n",
    "\n",
    "def e(state: State):\n",
    "    print(f'Adding \"E\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"E\"]}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(a)\n",
    "builder.add_node(b)\n",
    "builder.add_node(c)\n",
    "builder.add_node(d)\n",
    "builder.add_node(e)\n",
    "builder.add_edge(START, \"a\")\n",
    "\n",
    "\n",
    "def route_bc_or_cd(state: State) -> Sequence[str]:\n",
    "    if state[\"which\"] == \"cd\":\n",
    "        return [\"c\", \"d\"]\n",
    "    return [\"b\", \"c\"]\n",
    "\n",
    "\n",
    "intermediates = [\"b\", \"c\", \"d\"]\n",
    "builder.add_conditional_edges(\n",
    "    \"a\",\n",
    "    route_bc_or_cd,\n",
    "    intermediates,\n",
    ")\n",
    "for node in intermediates:\n",
    "    builder.add_edge(node, \"e\")\n",
    "\n",
    "builder.add_edge(\"e\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "graph.invoke({\"aggregate\": [], \"which\": \"cd\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99168421-11c5-4415-be7b-2222bca025d6",
   "metadata": {},
   "source": [
    "### Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a250380b-6279-4ddb-abda-f4f021bc5701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoints, threads and  checkpointers\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(node_a)\n",
    "workflow.add_node(node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "display(draw_graph(graph))\n",
    "\n",
    "# using a thread id allows us to store the checkpoints\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke({\"foo\": \"\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e09709ae-631b-45a6-a7ca-04b3aa254b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da98-6b42-8002-0d3cb4de97fa'}}, metadata={'source': 'loop', 'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}, 'step': 2, 'parents': {}, 'thread_id': '1'}, created_at='2025-04-10T03:11:00.144090+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da83-6636-8001-92abe6928ef2'}}, tasks=())"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the latest state\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "450d9589-8e5f-4f3a-bde4-70d8140cc0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da98-6b42-8002-0d3cb4de97fa'}}, metadata={'source': 'loop', 'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}, 'step': 2, 'parents': {}, 'thread_id': '1'}, created_at='2025-04-10T03:11:00.144090+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da83-6636-8001-92abe6928ef2'}}, tasks=()),\n",
       " StateSnapshot(values={'foo': 'a', 'bar': ['a']}, next=('node_b',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da83-6636-8001-92abe6928ef2'}}, metadata={'source': 'loop', 'writes': {'node_a': {'foo': 'a', 'bar': ['a']}}, 'step': 1, 'parents': {}, 'thread_id': '1'}, created_at='2025-04-10T03:11:00.135890+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da60-6096-8000-7672a4c64038'}}, tasks=(PregelTask(id='8f3b1d89-14dd-7ba5-9b1a-6a846611ba1b', name='node_b', path=('__pregel_pull', 'node_b'), error=None, interrupts=(), state=None, result={'foo': 'b', 'bar': ['b']}),)),\n",
       " StateSnapshot(values={'foo': '', 'bar': []}, next=('node_a',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da60-6096-8000-7672a4c64038'}}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}, 'thread_id': '1'}, created_at='2025-04-10T03:11:00.121410+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da4d-67b9-bfff-feed28041f03'}}, tasks=(PregelTask(id='e40e27b8-beef-5d2a-6829-321f104687cd', name='node_a', path=('__pregel_pull', 'node_a'), error=None, interrupts=(), state=None, result={'foo': 'a', 'bar': ['a']}),)),\n",
       " StateSnapshot(values={'bar': []}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da4d-67b9-bfff-feed28041f03'}}, metadata={'source': 'input', 'writes': {'__start__': {'foo': ''}}, 'step': -1, 'parents': {}, 'thread_id': '1'}, created_at='2025-04-10T03:11:00.113810+00:00', parent_config=None, tasks=(PregelTask(id='31f5007e-0981-f84b-6b7b-b3c9e4eeda0a', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'foo': ''}),))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get state history\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b095e88d-ed5e-4e6d-a22b-a8df2eee240d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'foo': '', 'bar': []}, next=('node_a',), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f015b96-da60-6096-8000-7672a4c64038'}}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}, 'thread_id': '1'}, created_at='2025-04-10T03:11:00.121410+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f015b96-da4d-67b9-bfff-feed28041f03'}}, tasks=(PregelTask(id='e40e27b8-beef-5d2a-6829-321f104687cd', name='node_a', path=('__pregel_pull', 'node_a'), error=None, interrupts=(), state=None, result={'foo': 'a', 'bar': ['a']}),))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the state at a specific checkpoint\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f015b96-da60-6096-8000-7672a4c64038\"}}\n",
    "graph.get_state(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d5965-82de-42fe-a6d0-c53e1f8165cd",
   "metadata": {},
   "source": [
    "Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "949476c3-cab3-420a-9283-064ff334e88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when we `replay`, it does not re-execute the graph until that point \n",
    "# it executes all the steps from that particular checkpoint though \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f015b96-da4d-67b9-bfff-feed28041f03\"}}\n",
    "graph.invoke(None, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9ca97-bc7e-4da3-a488-5bfaf91824ec",
   "metadata": {},
   "source": [
    "It's also possible to create \"long term\" memory where the state is persisted across the threads using a memory saver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf209dd6-d53f-4341-83a4-2b4a1a15d458",
   "metadata": {},
   "source": [
    "LangGraph currently supports in-memory, sqlite and postgres (for prod) memory savers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030374e-e3fa-4f0a-8bfb-39d2da5145d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195e0c7-710b-40e1-b445-cf444a694a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f194459-1ecd-40f0-b457-2fddc2a6e40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LG-env)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
